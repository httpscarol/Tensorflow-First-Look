{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOB0pAi8uv5aI1hxpe5PwtD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1 - Importing and Sorting Data**"
      ],
      "metadata": {
        "id": "ww0OiTlmu9fE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "v77bM6tJlpr6",
        "outputId": "189a11b4-3da1-4aa7-c18b-cf7d54762b10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Customer ID  Gender  Senior Citizen Partner Dependents  tenure  \\\n",
              "0     7590-VHVEA  Female               0     Yes         No       1   \n",
              "1     7590-VHVEG  Female               0     Yes         No       1   \n",
              "2     5575-GNVDE    Male               0      No         No      34   \n",
              "3     3668-QPYBK    Male               0      No         No       2   \n",
              "4     7795-CFOCW    Male               0      No         No      45   \n",
              "...          ...     ...             ...     ...        ...     ...   \n",
              "7039  6840-RESVB    Male               0     Yes        Yes      24   \n",
              "7040  2234-XADUH  Female               0     Yes        Yes      72   \n",
              "7041  4801-JZAZL  Female               0     Yes        Yes      11   \n",
              "7042  8361-LTMKD    Male               1     Yes         No       4   \n",
              "7043  3186-AJIEK    Male               0      No         No      66   \n",
              "\n",
              "     Phone Service    Multiple Lines Internet Service Online Security  ...  \\\n",
              "0               No  No phone service              DSL              No  ...   \n",
              "1               No  No phone service              DSL              No  ...   \n",
              "2              Yes                No              DSL             Yes  ...   \n",
              "3              Yes                No              DSL             Yes  ...   \n",
              "4               No  No phone service              DSL             Yes  ...   \n",
              "...            ...               ...              ...             ...  ...   \n",
              "7039           Yes               Yes              DSL             Yes  ...   \n",
              "7040           Yes               Yes      Fiber optic              No  ...   \n",
              "7041            No  No phone service              DSL             Yes  ...   \n",
              "7042           Yes               Yes      Fiber optic              No  ...   \n",
              "7043           Yes                No      Fiber optic             Yes  ...   \n",
              "\n",
              "     Device Protection Tech Support Streaming TV Streaming Movies  \\\n",
              "0                   No           No           No               No   \n",
              "1                   No           No           No               No   \n",
              "2                  Yes           No           No               No   \n",
              "3                   No           No           No               No   \n",
              "4                  Yes          Yes           No               No   \n",
              "...                ...          ...          ...              ...   \n",
              "7039               Yes          Yes          Yes              Yes   \n",
              "7040               Yes           No          Yes              Yes   \n",
              "7041                No           No           No               No   \n",
              "7042                No           No           No               No   \n",
              "7043               Yes          Yes          Yes              Yes   \n",
              "\n",
              "            Contract Paperless Billing             Payment Method  \\\n",
              "0     Month-to-month               Yes           Electronic check   \n",
              "1     Month-to-month               Yes           Electronic check   \n",
              "2           One year                No               Mailed check   \n",
              "3     Month-to-month               Yes               Mailed check   \n",
              "4           One year                No  Bank transfer (automatic)   \n",
              "...              ...               ...                        ...   \n",
              "7039        One year               Yes               Mailed check   \n",
              "7040        One year               Yes    Credit card (automatic)   \n",
              "7041  Month-to-month               Yes           Electronic check   \n",
              "7042  Month-to-month               Yes               Mailed check   \n",
              "7043        Two year               Yes  Bank transfer (automatic)   \n",
              "\n",
              "     Monthly Charges  Total Charges Churn  \n",
              "0              29.85          29.85    No  \n",
              "1              29.85          29.85    No  \n",
              "2              56.95         1889.5    No  \n",
              "3              53.85         108.15   Yes  \n",
              "4              42.30        1840.75    No  \n",
              "...              ...            ...   ...  \n",
              "7039           84.80         1990.5    No  \n",
              "7040          103.20         7362.9    No  \n",
              "7041           29.60         346.45    No  \n",
              "7042           74.40          306.6   Yes  \n",
              "7043          105.65         6844.5    No  \n",
              "\n",
              "[7044 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-333c37ce-b6cf-4acc-986f-7b63dc106788\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Senior Citizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>Phone Service</th>\n",
              "      <th>Multiple Lines</th>\n",
              "      <th>Internet Service</th>\n",
              "      <th>Online Security</th>\n",
              "      <th>...</th>\n",
              "      <th>Device Protection</th>\n",
              "      <th>Tech Support</th>\n",
              "      <th>Streaming TV</th>\n",
              "      <th>Streaming Movies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>Paperless Billing</th>\n",
              "      <th>Payment Method</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Total Charges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEA</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7039</th>\n",
              "      <td>6840-RESVB</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>24</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>84.80</td>\n",
              "      <td>1990.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7040</th>\n",
              "      <td>2234-XADUH</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>72</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit card (automatic)</td>\n",
              "      <td>103.20</td>\n",
              "      <td>7362.9</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7041</th>\n",
              "      <td>4801-JZAZL</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.60</td>\n",
              "      <td>346.45</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7042</th>\n",
              "      <td>8361-LTMKD</td>\n",
              "      <td>Male</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>74.40</td>\n",
              "      <td>306.6</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7043</th>\n",
              "      <td>3186-AJIEK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>66</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>105.65</td>\n",
              "      <td>6844.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7044 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-333c37ce-b6cf-4acc-986f-7b63dc106788')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-333c37ce-b6cf-4acc-986f-7b63dc106788 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-333c37ce-b6cf-4acc-986f-7b63dc106788');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import pandas as pds\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pds.read_csv('https://raw.githubusercontent.com/httpscarol/Tensorflow-First-Look/main/Churn.csv')\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pds.get_dummies(df.drop(['Churn', 'Customer ID'], axis=1))\n",
        "\n",
        "classify = df['Churn'].apply(lambda x:1 if x=='Yes' else 0)"
      ],
      "metadata": {
        "id": "37WRSC9zm9ps"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_treino, dados_teste, classify_treino, classify_teste = train_test_split(dados, classify, test_size=.2)"
      ],
      "metadata": {
        "id": "_FR1mtvVrjfW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados_treino.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "F2OW5aQzr_RV",
        "outputId": "cc325685-986c-492f-8ec2-1f3ead78beb0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Senior Citizen  tenure  Monthly Charges  Gender_Female  Gender_Male  \\\n",
              "3100               0      17            20.15              1            0   \n",
              "1056               0      36            19.55              1            0   \n",
              "5112               1      47            85.50              0            1   \n",
              "5113               0       7            20.05              1            0   \n",
              "6665               0      36           104.80              1            0   \n",
              "\n",
              "      Partner_No  Partner_Yes  Dependents_No  Dependents_Yes  \\\n",
              "3100           1            0              1               0   \n",
              "1056           1            0              1               0   \n",
              "5112           1            0              1               0   \n",
              "5113           1            0              1               0   \n",
              "6665           1            0              1               0   \n",
              "\n",
              "      Phone Service_No  ...  Total Charges_995.35  Total Charges_996.45  \\\n",
              "3100                 0  ...                     0                     0   \n",
              "1056                 0  ...                     0                     0   \n",
              "5112                 0  ...                     0                     0   \n",
              "5113                 0  ...                     0                     0   \n",
              "6665                 0  ...                     0                     0   \n",
              "\n",
              "      Total Charges_996.85  Total Charges_996.95  Total Charges_997.65  \\\n",
              "3100                     0                     0                     0   \n",
              "1056                     0                     0                     0   \n",
              "5112                     0                     0                     0   \n",
              "5113                     0                     0                     0   \n",
              "6665                     0                     0                     0   \n",
              "\n",
              "      Total Charges_997.75  Total Charges_998.1  Total Charges_999.45  \\\n",
              "3100                     0                    0                     0   \n",
              "1056                     0                    0                     0   \n",
              "5112                     0                    0                     0   \n",
              "5113                     0                    0                     0   \n",
              "6665                     0                    0                     0   \n",
              "\n",
              "      Total Charges_999.8  Total Charges_999.9  \n",
              "3100                    0                    0  \n",
              "1056                    0                    0  \n",
              "5112                    0                    0  \n",
              "5113                    0                    0  \n",
              "6665                    0                    0  \n",
              "\n",
              "[5 rows x 6575 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8706e6a-30d2-4199-a657-b927b3f2da5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Senior Citizen</th>\n",
              "      <th>tenure</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>Partner_No</th>\n",
              "      <th>Partner_Yes</th>\n",
              "      <th>Dependents_No</th>\n",
              "      <th>Dependents_Yes</th>\n",
              "      <th>Phone Service_No</th>\n",
              "      <th>...</th>\n",
              "      <th>Total Charges_995.35</th>\n",
              "      <th>Total Charges_996.45</th>\n",
              "      <th>Total Charges_996.85</th>\n",
              "      <th>Total Charges_996.95</th>\n",
              "      <th>Total Charges_997.65</th>\n",
              "      <th>Total Charges_997.75</th>\n",
              "      <th>Total Charges_998.1</th>\n",
              "      <th>Total Charges_999.45</th>\n",
              "      <th>Total Charges_999.8</th>\n",
              "      <th>Total Charges_999.9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3100</th>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>20.15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>19.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5112</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>85.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5113</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>20.05</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6665</th>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>104.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 6575 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8706e6a-30d2-4199-a657-b927b3f2da5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8706e6a-30d2-4199-a657-b927b3f2da5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8706e6a-30d2-4199-a657-b927b3f2da5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_treino.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSmHkNegsJkE",
        "outputId": "533949c3-c2d6-4d42-dc67-68532ff5bed2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3100    0\n",
              "1056    0\n",
              "5112    1\n",
              "5113    1\n",
              "6665    0\n",
              "Name: Churn, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2 - Importing Dependencies**"
      ],
      "metadata": {
        "id": "Y55jy_zOwlyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "#Core model class, e load_model para rodar o modelo da memória. Dense é uma camada conectada dentro da rede neural\n",
        "#que permite que sejam construidas muitas camadas escondidas nela. Por último accuracy_score é a metrica utilizada\n",
        "#para conferir/avaliar se a acurácia do programa está boa."
      ],
      "metadata": {
        "id": "Q0qPQNGY78-o"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3 - Construindo e Compilando o Modelo**"
      ],
      "metadata": {
        "id": "bk2wZxi21MbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()  #Instanciando a rede neural.\n",
        "\n",
        "model.add(Dense(units=32, activation='relu',input_dim=len(dados_treino.columns))) \n",
        "#Adicionando uma camada com 32 neurons, ativando os dados de um input \"raw\" modificando para tal maneira que faça \n",
        "#uma função na qual seu gráfico comece no 0 e vá numa reta ate +infinito, e definindo que a dimenção do input passado\n",
        "#sera a mesma que as colunas do dataset.\n",
        "\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "#Adicionando uma camada com 64 neurons, e de novo ativando de tal maneira que seu gráfico comece no 0 e vá ate +infinito.\n",
        "\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "#Esse último especifica como vai retornar, que no caso sera em 1resultado, pois queremos saber a probabilidade de Churn de alguem."
      ],
      "metadata": {
        "id": "2Vo38hhxwp_3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
      ],
      "metadata": {
        "id": "8Z93UAb35Gkv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4 - Treinando, Prevendo e Avaliando**"
      ],
      "metadata": {
        "id": "7nsvVIzh8D_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dados_treino, classify_treino, epochs=350, batch_size=32)\n",
        "\n",
        "#Treinando o modelo utilizando a função fit. Epochs são o tanto de vezes que ele ira testar, inicialmente tentei com 200 e 350.\n",
        "#batch size seria o tamanho que ele pegaria de neurons."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UCJlPJ69V7Z",
        "outputId": "c6236c74-80ba-4795-ecc7-13d72a5844f9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4811 - accuracy: 0.7760\n",
            "Epoch 2/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4761 - accuracy: 0.7776\n",
            "Epoch 3/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4741 - accuracy: 0.7817\n",
            "Epoch 4/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4708 - accuracy: 0.7856\n",
            "Epoch 5/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4663 - accuracy: 0.7835\n",
            "Epoch 6/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4616 - accuracy: 0.7890\n",
            "Epoch 7/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4651 - accuracy: 0.7853\n",
            "Epoch 8/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4593 - accuracy: 0.7847\n",
            "Epoch 9/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.7817\n",
            "Epoch 10/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4579 - accuracy: 0.7863\n",
            "Epoch 11/350\n",
            "177/177 [==============================] - 2s 10ms/step - loss: 0.4577 - accuracy: 0.7842\n",
            "Epoch 12/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4565 - accuracy: 0.7844\n",
            "Epoch 13/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4521 - accuracy: 0.7863\n",
            "Epoch 14/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4542 - accuracy: 0.7823\n",
            "Epoch 15/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.7831\n",
            "Epoch 16/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.7865\n",
            "Epoch 17/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4509 - accuracy: 0.7878\n",
            "Epoch 18/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4481 - accuracy: 0.7909\n",
            "Epoch 19/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.7895\n",
            "Epoch 20/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.7842\n",
            "Epoch 21/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4504 - accuracy: 0.7867\n",
            "Epoch 22/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4471 - accuracy: 0.7865\n",
            "Epoch 23/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4455 - accuracy: 0.7869\n",
            "Epoch 24/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.7888\n",
            "Epoch 25/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4462 - accuracy: 0.7886\n",
            "Epoch 26/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4468 - accuracy: 0.7906\n",
            "Epoch 27/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4480 - accuracy: 0.7874\n",
            "Epoch 28/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.7870\n",
            "Epoch 29/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4438 - accuracy: 0.7902\n",
            "Epoch 30/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4452 - accuracy: 0.7870\n",
            "Epoch 31/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4428 - accuracy: 0.7901\n",
            "Epoch 32/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4420 - accuracy: 0.7879\n",
            "Epoch 33/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4428 - accuracy: 0.7878\n",
            "Epoch 34/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.7901\n",
            "Epoch 35/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4417 - accuracy: 0.7888\n",
            "Epoch 36/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4417 - accuracy: 0.7929\n",
            "Epoch 37/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.7890\n",
            "Epoch 38/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4440 - accuracy: 0.7856\n",
            "Epoch 39/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4397 - accuracy: 0.7911\n",
            "Epoch 40/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4407 - accuracy: 0.7860\n",
            "Epoch 41/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.7938\n",
            "Epoch 42/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4465 - accuracy: 0.7906\n",
            "Epoch 43/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4435 - accuracy: 0.7911\n",
            "Epoch 44/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4418 - accuracy: 0.7879\n",
            "Epoch 45/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.7915\n",
            "Epoch 46/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4406 - accuracy: 0.7888\n",
            "Epoch 47/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4398 - accuracy: 0.7917\n",
            "Epoch 48/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4474 - accuracy: 0.7865\n",
            "Epoch 49/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4383 - accuracy: 0.7899\n",
            "Epoch 50/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4371 - accuracy: 0.7917\n",
            "Epoch 51/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4374 - accuracy: 0.7922\n",
            "Epoch 52/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4363 - accuracy: 0.7970\n",
            "Epoch 53/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4371 - accuracy: 0.7922\n",
            "Epoch 54/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4381 - accuracy: 0.7924\n",
            "Epoch 55/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4366 - accuracy: 0.7959\n",
            "Epoch 56/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.7902\n",
            "Epoch 57/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4341 - accuracy: 0.7904\n",
            "Epoch 58/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4364 - accuracy: 0.7938\n",
            "Epoch 59/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4371 - accuracy: 0.7929\n",
            "Epoch 60/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4368 - accuracy: 0.7945\n",
            "Epoch 61/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4362 - accuracy: 0.7897\n",
            "Epoch 62/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4379 - accuracy: 0.7929\n",
            "Epoch 63/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4338 - accuracy: 0.7973\n",
            "Epoch 64/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4381 - accuracy: 0.7917\n",
            "Epoch 65/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.7934\n",
            "Epoch 66/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.7927\n",
            "Epoch 67/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4342 - accuracy: 0.7925\n",
            "Epoch 68/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4335 - accuracy: 0.7949\n",
            "Epoch 69/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4357 - accuracy: 0.7945\n",
            "Epoch 70/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.7913\n",
            "Epoch 71/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.7934\n",
            "Epoch 72/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4336 - accuracy: 0.7954\n",
            "Epoch 73/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4335 - accuracy: 0.7959\n",
            "Epoch 74/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.7972\n",
            "Epoch 75/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4341 - accuracy: 0.7954\n",
            "Epoch 76/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4304 - accuracy: 0.7972\n",
            "Epoch 77/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4301 - accuracy: 0.7933\n",
            "Epoch 78/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4319 - accuracy: 0.7984\n",
            "Epoch 79/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4307 - accuracy: 0.7972\n",
            "Epoch 80/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4308 - accuracy: 0.7979\n",
            "Epoch 81/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4291 - accuracy: 0.7986\n",
            "Epoch 82/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4337 - accuracy: 0.7963\n",
            "Epoch 83/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.8005\n",
            "Epoch 84/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4328 - accuracy: 0.7965\n",
            "Epoch 85/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4346 - accuracy: 0.7947\n",
            "Epoch 86/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4298 - accuracy: 0.7979\n",
            "Epoch 87/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4285 - accuracy: 0.7970\n",
            "Epoch 88/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4311 - accuracy: 0.7954\n",
            "Epoch 89/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4298 - accuracy: 0.7954\n",
            "Epoch 90/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4288 - accuracy: 0.8000\n",
            "Epoch 91/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4314 - accuracy: 0.7952\n",
            "Epoch 92/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4276 - accuracy: 0.7996\n",
            "Epoch 93/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4306 - accuracy: 0.7945\n",
            "Epoch 94/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4305 - accuracy: 0.7957\n",
            "Epoch 95/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.7980\n",
            "Epoch 96/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4279 - accuracy: 0.8002\n",
            "Epoch 97/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.7982\n",
            "Epoch 98/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4294 - accuracy: 0.7947\n",
            "Epoch 99/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4273 - accuracy: 0.7989\n",
            "Epoch 100/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4253 - accuracy: 0.7938\n",
            "Epoch 101/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.7988\n",
            "Epoch 102/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8002\n",
            "Epoch 103/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.7945\n",
            "Epoch 104/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8005\n",
            "Epoch 105/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4278 - accuracy: 0.7959\n",
            "Epoch 106/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4267 - accuracy: 0.7984\n",
            "Epoch 107/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.7993\n",
            "Epoch 108/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4283 - accuracy: 0.7972\n",
            "Epoch 109/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.7995\n",
            "Epoch 110/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4255 - accuracy: 0.7975\n",
            "Epoch 111/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4282 - accuracy: 0.7970\n",
            "Epoch 112/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.7963\n",
            "Epoch 113/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4251 - accuracy: 0.7986\n",
            "Epoch 114/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4273 - accuracy: 0.7989\n",
            "Epoch 115/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.7975\n",
            "Epoch 116/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4249 - accuracy: 0.8023\n",
            "Epoch 117/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4281 - accuracy: 0.7954\n",
            "Epoch 118/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4263 - accuracy: 0.8000\n",
            "Epoch 119/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4231 - accuracy: 0.8020\n",
            "Epoch 120/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4238 - accuracy: 0.8014\n",
            "Epoch 121/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4263 - accuracy: 0.7998\n",
            "Epoch 122/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4277 - accuracy: 0.7966\n",
            "Epoch 123/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4280 - accuracy: 0.7959\n",
            "Epoch 124/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4244 - accuracy: 0.7998\n",
            "Epoch 125/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4236 - accuracy: 0.8007\n",
            "Epoch 126/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4251 - accuracy: 0.8018\n",
            "Epoch 127/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4239 - accuracy: 0.8002\n",
            "Epoch 128/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4258 - accuracy: 0.8032\n",
            "Epoch 129/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.8014\n",
            "Epoch 130/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.8000\n",
            "Epoch 131/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4248 - accuracy: 0.7963\n",
            "Epoch 132/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.8020\n",
            "Epoch 133/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.7995\n",
            "Epoch 134/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4277 - accuracy: 0.7972\n",
            "Epoch 135/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4267 - accuracy: 0.8005\n",
            "Epoch 136/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4243 - accuracy: 0.7979\n",
            "Epoch 137/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.7995\n",
            "Epoch 138/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.8009\n",
            "Epoch 139/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4236 - accuracy: 0.7984\n",
            "Epoch 140/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4258 - accuracy: 0.8002\n",
            "Epoch 141/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4224 - accuracy: 0.8037\n",
            "Epoch 142/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4237 - accuracy: 0.7961\n",
            "Epoch 143/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4240 - accuracy: 0.7975\n",
            "Epoch 144/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.8035\n",
            "Epoch 145/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4262 - accuracy: 0.7972\n",
            "Epoch 146/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8004\n",
            "Epoch 147/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4205 - accuracy: 0.8016\n",
            "Epoch 148/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4239 - accuracy: 0.8037\n",
            "Epoch 149/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8005\n",
            "Epoch 150/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4259 - accuracy: 0.7966\n",
            "Epoch 151/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4251 - accuracy: 0.7965\n",
            "Epoch 152/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.7995\n",
            "Epoch 153/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4230 - accuracy: 0.8007\n",
            "Epoch 154/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8059\n",
            "Epoch 155/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.8011\n",
            "Epoch 156/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4235 - accuracy: 0.8009\n",
            "Epoch 157/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.7998\n",
            "Epoch 158/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8032\n",
            "Epoch 159/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8023\n",
            "Epoch 160/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4214 - accuracy: 0.8009\n",
            "Epoch 161/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4224 - accuracy: 0.8032\n",
            "Epoch 162/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.8004\n",
            "Epoch 163/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4199 - accuracy: 0.7984\n",
            "Epoch 164/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.7995\n",
            "Epoch 165/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.8005\n",
            "Epoch 166/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.7984\n",
            "Epoch 167/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4233 - accuracy: 0.7986\n",
            "Epoch 168/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8021\n",
            "Epoch 169/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8041\n",
            "Epoch 170/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4229 - accuracy: 0.8009\n",
            "Epoch 171/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4217 - accuracy: 0.7984\n",
            "Epoch 172/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4225 - accuracy: 0.8041\n",
            "Epoch 173/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4240 - accuracy: 0.8002\n",
            "Epoch 174/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.8012\n",
            "Epoch 175/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4239 - accuracy: 0.7998\n",
            "Epoch 176/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8012\n",
            "Epoch 177/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4230 - accuracy: 0.7968\n",
            "Epoch 178/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.7998\n",
            "Epoch 179/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8012\n",
            "Epoch 180/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4226 - accuracy: 0.8000\n",
            "Epoch 181/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4210 - accuracy: 0.8085\n",
            "Epoch 182/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.8018\n",
            "Epoch 183/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.7996\n",
            "Epoch 184/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4231 - accuracy: 0.7988\n",
            "Epoch 185/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4211 - accuracy: 0.8005\n",
            "Epoch 186/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4188 - accuracy: 0.8043\n",
            "Epoch 187/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4207 - accuracy: 0.8011\n",
            "Epoch 188/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4204 - accuracy: 0.8025\n",
            "Epoch 189/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4197 - accuracy: 0.8021\n",
            "Epoch 190/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.7975\n",
            "Epoch 191/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4186 - accuracy: 0.8014\n",
            "Epoch 192/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.8028\n",
            "Epoch 193/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4207 - accuracy: 0.8002\n",
            "Epoch 194/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8046\n",
            "Epoch 195/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8044\n",
            "Epoch 196/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4166 - accuracy: 0.8046\n",
            "Epoch 197/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4197 - accuracy: 0.8027\n",
            "Epoch 198/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4201 - accuracy: 0.8005\n",
            "Epoch 199/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.7989\n",
            "Epoch 200/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8023\n",
            "Epoch 201/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.7979\n",
            "Epoch 202/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4209 - accuracy: 0.8048\n",
            "Epoch 203/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8023\n",
            "Epoch 204/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4179 - accuracy: 0.8043\n",
            "Epoch 205/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4205 - accuracy: 0.8007\n",
            "Epoch 206/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4209 - accuracy: 0.8034\n",
            "Epoch 207/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4205 - accuracy: 0.7988\n",
            "Epoch 208/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8012\n",
            "Epoch 209/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4197 - accuracy: 0.8004\n",
            "Epoch 210/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8053\n",
            "Epoch 211/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8043\n",
            "Epoch 212/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4227 - accuracy: 0.7996\n",
            "Epoch 213/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4198 - accuracy: 0.8007\n",
            "Epoch 214/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.7965\n",
            "Epoch 215/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.7965\n",
            "Epoch 216/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8030\n",
            "Epoch 217/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4200 - accuracy: 0.8004\n",
            "Epoch 218/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8046\n",
            "Epoch 219/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4182 - accuracy: 0.8030\n",
            "Epoch 220/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8009\n",
            "Epoch 221/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4204 - accuracy: 0.8020\n",
            "Epoch 222/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4175 - accuracy: 0.8032\n",
            "Epoch 223/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4164 - accuracy: 0.8051\n",
            "Epoch 224/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4185 - accuracy: 0.8025\n",
            "Epoch 225/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4180 - accuracy: 0.8021\n",
            "Epoch 226/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8016\n",
            "Epoch 227/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8060\n",
            "Epoch 228/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8039\n",
            "Epoch 229/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4196 - accuracy: 0.8021\n",
            "Epoch 230/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4194 - accuracy: 0.8055\n",
            "Epoch 231/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.8041\n",
            "Epoch 232/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4160 - accuracy: 0.8018\n",
            "Epoch 233/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4171 - accuracy: 0.8057\n",
            "Epoch 234/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4173 - accuracy: 0.8007\n",
            "Epoch 235/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.7993\n",
            "Epoch 236/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4200 - accuracy: 0.7986\n",
            "Epoch 237/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.8034\n",
            "Epoch 238/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4179 - accuracy: 0.8055\n",
            "Epoch 239/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4190 - accuracy: 0.8046\n",
            "Epoch 240/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.8012\n",
            "Epoch 241/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4189 - accuracy: 0.8025\n",
            "Epoch 242/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4211 - accuracy: 0.8025\n",
            "Epoch 243/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4167 - accuracy: 0.8076\n",
            "Epoch 244/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4143 - accuracy: 0.8034\n",
            "Epoch 245/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4165 - accuracy: 0.8044\n",
            "Epoch 246/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4172 - accuracy: 0.8064\n",
            "Epoch 247/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8020\n",
            "Epoch 248/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8020\n",
            "Epoch 249/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8007\n",
            "Epoch 250/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4188 - accuracy: 0.8011\n",
            "Epoch 251/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8043\n",
            "Epoch 252/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8000\n",
            "Epoch 253/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.7966\n",
            "Epoch 254/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8007\n",
            "Epoch 255/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4158 - accuracy: 0.8028\n",
            "Epoch 256/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8025\n",
            "Epoch 257/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4170 - accuracy: 0.8041\n",
            "Epoch 258/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4186 - accuracy: 0.8053\n",
            "Epoch 259/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4157 - accuracy: 0.8044\n",
            "Epoch 260/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4165 - accuracy: 0.8027\n",
            "Epoch 261/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4169 - accuracy: 0.8018\n",
            "Epoch 262/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.8025\n",
            "Epoch 263/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.8032\n",
            "Epoch 264/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4178 - accuracy: 0.8050\n",
            "Epoch 265/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8030\n",
            "Epoch 266/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8011\n",
            "Epoch 267/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8014\n",
            "Epoch 268/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8027\n",
            "Epoch 269/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4170 - accuracy: 0.7980\n",
            "Epoch 270/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4166 - accuracy: 0.8021\n",
            "Epoch 271/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4157 - accuracy: 0.8018\n",
            "Epoch 272/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8059\n",
            "Epoch 273/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4147 - accuracy: 0.8041\n",
            "Epoch 274/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8057\n",
            "Epoch 275/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8016\n",
            "Epoch 276/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4161 - accuracy: 0.7993\n",
            "Epoch 277/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8057\n",
            "Epoch 278/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8059\n",
            "Epoch 279/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8032\n",
            "Epoch 280/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4153 - accuracy: 0.8046\n",
            "Epoch 281/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4173 - accuracy: 0.7988\n",
            "Epoch 282/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4155 - accuracy: 0.8027\n",
            "Epoch 283/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4147 - accuracy: 0.8064\n",
            "Epoch 284/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4147 - accuracy: 0.8030\n",
            "Epoch 285/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8025\n",
            "Epoch 286/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8046\n",
            "Epoch 287/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4142 - accuracy: 0.8057\n",
            "Epoch 288/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8027\n",
            "Epoch 289/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8016\n",
            "Epoch 290/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8021\n",
            "Epoch 291/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4135 - accuracy: 0.8043\n",
            "Epoch 292/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4149 - accuracy: 0.8071\n",
            "Epoch 293/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4266 - accuracy: 0.8014\n",
            "Epoch 294/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4152 - accuracy: 0.8021\n",
            "Epoch 295/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4151 - accuracy: 0.8067\n",
            "Epoch 296/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.7996\n",
            "Epoch 297/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8062\n",
            "Epoch 298/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4159 - accuracy: 0.8034\n",
            "Epoch 299/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8085\n",
            "Epoch 300/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4137 - accuracy: 0.8032\n",
            "Epoch 301/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4128 - accuracy: 0.8018\n",
            "Epoch 302/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4141 - accuracy: 0.8027\n",
            "Epoch 303/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8050\n",
            "Epoch 304/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4134 - accuracy: 0.8051\n",
            "Epoch 305/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8018\n",
            "Epoch 306/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4168 - accuracy: 0.8034\n",
            "Epoch 307/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4148 - accuracy: 0.8037\n",
            "Epoch 308/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4136 - accuracy: 0.8037\n",
            "Epoch 309/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8041\n",
            "Epoch 310/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4155 - accuracy: 0.8028\n",
            "Epoch 311/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8055\n",
            "Epoch 312/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4144 - accuracy: 0.8069\n",
            "Epoch 313/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8048\n",
            "Epoch 314/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4153 - accuracy: 0.8044\n",
            "Epoch 315/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4138 - accuracy: 0.8030\n",
            "Epoch 316/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8025\n",
            "Epoch 317/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8037\n",
            "Epoch 318/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4121 - accuracy: 0.8043\n",
            "Epoch 319/350\n",
            "177/177 [==============================] - 2s 9ms/step - loss: 0.4150 - accuracy: 0.8037\n",
            "Epoch 320/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4147 - accuracy: 0.8035\n",
            "Epoch 321/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8039\n",
            "Epoch 322/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8018\n",
            "Epoch 323/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8041\n",
            "Epoch 324/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4183 - accuracy: 0.8014\n",
            "Epoch 325/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8025\n",
            "Epoch 326/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8043\n",
            "Epoch 327/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4179 - accuracy: 0.8034\n",
            "Epoch 328/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8059\n",
            "Epoch 329/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8014\n",
            "Epoch 330/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8076\n",
            "Epoch 331/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4151 - accuracy: 0.8002\n",
            "Epoch 332/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4159 - accuracy: 0.8048\n",
            "Epoch 333/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4176 - accuracy: 0.8044\n",
            "Epoch 334/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4133 - accuracy: 0.8060\n",
            "Epoch 335/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4143 - accuracy: 0.8053\n",
            "Epoch 336/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4151 - accuracy: 0.8032\n",
            "Epoch 337/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4134 - accuracy: 0.8025\n",
            "Epoch 338/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4128 - accuracy: 0.8060\n",
            "Epoch 339/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4156 - accuracy: 0.8009\n",
            "Epoch 340/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4108 - accuracy: 0.8046\n",
            "Epoch 341/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8009\n",
            "Epoch 342/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8053\n",
            "Epoch 343/350\n",
            "177/177 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8035\n",
            "Epoch 344/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4144 - accuracy: 0.8053\n",
            "Epoch 345/350\n",
            "177/177 [==============================] - 1s 8ms/step - loss: 0.4125 - accuracy: 0.8062\n",
            "Epoch 346/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4113 - accuracy: 0.8044\n",
            "Epoch 347/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4126 - accuracy: 0.8028\n",
            "Epoch 348/350\n",
            "177/177 [==============================] - 1s 7ms/step - loss: 0.4145 - accuracy: 0.8009\n",
            "Epoch 349/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4141 - accuracy: 0.8035\n",
            "Epoch 350/350\n",
            "177/177 [==============================] - 1s 6ms/step - loss: 0.4129 - accuracy: 0.8059\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa0df928220>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify_hat = model.predict(dados_teste)  \n",
        "# Fazendo uma previsão do modelo e armazenando nessa variavel classify_hat.\n",
        "classify_hat = [0 if val < 0.5 else 1 for val in classify_hat]\n",
        "# Retornando apenas 0 ou 1 dependendo do resultado, para obter um resultado binario.\n",
        "classify_hat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qV2Io1H_kh0",
        "outputId": "ac92fc4b-e601-4375-f372-89c7f31761b6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(classify_teste,classify_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m88ezTyXAg1O",
        "outputId": "a28540f3-f3cf-45e1-e109-551a2d2e6aa3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7977288857345636"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5 - Salvando e Rodando novamente**"
      ],
      "metadata": {
        "id": "F74u3LJWAw9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('tfTreino')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lxCUMXYA82F",
        "outputId": "3659abf1-453d-4106-d37e-adb2ad4aac42"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "sYR_M7iJBPy2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('tfTreino')"
      ],
      "metadata": {
        "id": "XF14SSlMBavW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse passo, salvamos o modelo como 'tfTreino' de modo que podemos deletar o modelo do codigo mas caso queiramos rodar de novo, precisamos apenas chamar a função \"load_model()\"."
      ],
      "metadata": {
        "id": "emFQpsHwBr2f"
      }
    }
  ]
}